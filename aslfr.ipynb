{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":52950,"databundleVersionId":5973250,"sourceType":"competition"},{"sourceId":6182721,"sourceType":"datasetVersion","datasetId":3497052},{"sourceId":6218997,"sourceType":"datasetVersion","datasetId":3571533},{"sourceId":6219756,"sourceType":"datasetVersion","datasetId":3572002},{"sourceId":6224776,"sourceType":"datasetVersion","datasetId":3575259},{"sourceId":6229131,"sourceType":"datasetVersion","datasetId":3578038},{"sourceId":6234831,"sourceType":"datasetVersion","datasetId":3581641},{"sourceId":6237906,"sourceType":"datasetVersion","datasetId":3583741},{"sourceId":6240056,"sourceType":"datasetVersion","datasetId":3585066},{"sourceId":6240386,"sourceType":"datasetVersion","datasetId":3585278},{"sourceId":6246547,"sourceType":"datasetVersion","datasetId":3589327},{"sourceId":6252468,"sourceType":"datasetVersion","datasetId":3593139},{"sourceId":6258326,"sourceType":"datasetVersion","datasetId":3596941},{"sourceId":6258375,"sourceType":"datasetVersion","datasetId":3596969},{"sourceId":6259755,"sourceType":"datasetVersion","datasetId":3597830},{"sourceId":6261459,"sourceType":"datasetVersion","datasetId":3598815},{"sourceId":6262776,"sourceType":"datasetVersion","datasetId":3599707},{"sourceId":6273458,"sourceType":"datasetVersion","datasetId":3606512},{"sourceId":6308356,"sourceType":"datasetVersion","datasetId":3629460},{"sourceId":6316275,"sourceType":"datasetVersion","datasetId":3631004},{"sourceId":6318990,"sourceType":"datasetVersion","datasetId":3636287},{"sourceId":6318999,"sourceType":"datasetVersion","datasetId":3636294},{"sourceId":6360134,"sourceType":"datasetVersion","datasetId":3643435}],"dockerImageVersionId":30513,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport json\nimport math\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport Levenshtein as lev\n\n\nfrom IPython.display import HTML\nimport matplotlib.animation as animation\nfrom matplotlib.animation import FuncAnimation\nimport glob\nimport random","metadata":{"_uuid":"d7ceeb15-6a24-40ec-892f-1e886210f4ef","_cell_guid":"858bf5f3-0fae-44d3-8b48-34807912d729","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"pre_process_fntrain\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH=\"/kaggle/input/asl-fingerspelling/\"\nBASE_PATH_DATA = \"/kaggle/input/aslfr-dataset-tfrecords/\"","metadata":{"_uuid":"e188c69b-82e2-49db-8909-b6cfdef776e9","_cell_guid":"e8141e67-b411-4727-8e58-7b99a3605ef0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open (BASE_PATH+\"character_to_prediction_index.json\", \"r\") as f:\n    char_to_num = json.load(f)\n\npad_token = '^'\npad_token_idx = 59\n\nchar_to_num[pad_token] = pad_token_idx\n\nnum_to_char = {j:i for i,j in char_to_num.items()}\ndf = pd.read_csv(BASE_PATH+\"train.csv\")\n\nLIP = [\n    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n]\nLPOSE = [13, 15, 17, 19, 21]\nRPOSE = [14, 16, 18, 20, 22]\nPOSE = LPOSE + RPOSE\n\nX = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE] + [f'x_face_{i}' for i in LIP]\nY = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE] + [f'y_face_{i}' for i in LIP]\nZ = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE] + [f'z_face_{i}' for i in LIP]\n\nSEL_COLS = X + Y + Z\nFRAME_LEN = 128\nNUM_AXIS = 2\nMAX_PHRASE_LENGTH = 64\n\nLIP_IDX_X   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"x\" in col]\nRHAND_IDX_X = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"x\" in col]\nLHAND_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"x\" in col]\nRPOSE_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"x\" in col]\nLPOSE_IDX_X = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"x\" in col]\n\nLIP_IDX_Y   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"y\" in col]\nRHAND_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"y\" in col]\nLHAND_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"y\" in col]\nRPOSE_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"y\" in col]\nLPOSE_IDX_Y = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"y\" in col]\n\nLIP_IDX_Z   = [i for i, col in enumerate(SEL_COLS)  if  \"face\" in col and \"z\" in col]\nRHAND_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if \"right\" in col and \"z\" in col]\nLHAND_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"left\" in col and \"z\" in col]\nRPOSE_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in RPOSE and \"z\" in col]\nLPOSE_IDX_Z = [i for i, col in enumerate(SEL_COLS)  if  \"pose\" in col and int(col[-2:]) in LPOSE and \"z\" in col]\n\nRHM = np.load(BASE_PATH_DATA+\"mean_std/rh_mean.npy\")\nLHM = np.load(BASE_PATH_DATA+\"mean_std/lh_mean.npy\")\nRPM = np.load(BASE_PATH_DATA+\"mean_std/rp_mean.npy\")\nLPM = np.load(BASE_PATH_DATA+\"mean_std/lp_mean.npy\")\nLIPM = np.load(BASE_PATH_DATA+\"mean_std/lip_mean.npy\")\n\nRHS = np.load(BASE_PATH_DATA+\"mean_std/rh_std.npy\")\nLHS = np.load(BASE_PATH_DATA+\"mean_std/lh_std.npy\")\nRPS = np.load(BASE_PATH_DATA+\"mean_std/rp_std.npy\")\nLPS = np.load(BASE_PATH_DATA+\"mean_std/lp_std.npy\")\nLIPS = np.load(BASE_PATH_DATA+\"mean_std/lip_std.npy\")\n\n\nLIP_IDX  = list(range(0,40))\nRHAND_IDX = list(range(40,61))\nLHAND_IDX = list(range(61,82))\nRPOSE_IDX = list(range(82,87))\nLPOSE_IDX = list(range(87,92))","metadata":{"_uuid":"762ab7b5-8ff2-49d0-82d6-aa0fa0ef2a3d","_cell_guid":"2e319dd8-d502-44e6-8ef6-d1fddd2a4673","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANIMATE","metadata":{"_uuid":"cf105dd3-79d1-4bb2-962e-221a2d40fcff","_cell_guid":"b1461165-dbab-4a75-a5da-7846792b62bb","trusted":true}},{"cell_type":"code","source":"fig, ax = plt.subplots()\nedges = [(0,1),(1,2),(2,3),(3,4),(0,5),(0,17),(5,6),(6,7),(7,8),(5,9),(9,10),(10,11),(11,12),\n         (9,13),(13,14),(14,15),(15,16),(13,17),(17,18),(18,19),(19,20)]\n\ndef plot_frame(frame, edges=[], idxs=[]):\n    x = frame[0:21]\n    y = frame[21:]\n    ax.clear()\n    \n    ax.scatter(x, y, color='dodgerblue')\n    if len(idxs) == 0:\n        idxs = list(range(len(x)))\n        \n    for i in range(len(x)):\n        ax.text(x[i], y[i], idxs[i])\n\n    for edge in edges:\n        ax.plot([x[edge[0]], x[edge[1]]], [y[edge[0]], y[edge[1]]], color='salmon')\n        \n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    plt.show()\n    \n    \ndef animate_frames(frames, edges=[], idxs=[]):\n    anim = FuncAnimation(fig, lambda frame: plot_frame(frame,edges), frames=frames, interval=100)\n    return HTML(anim.to_jshtml())","metadata":{"_uuid":"182c94aa-9e7b-4b3e-8075-5ef5776858c9","_cell_guid":"7cef8cde-730b-4d97-bf51-00b6e0671570","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_relevant_data_subset(pq_path):\n    return pd.read_parquet(pq_path, columns=SEL_COLS)\n\nfile_id = df.file_id.iloc[0]\ninpdir = BASE_PATH+\"train_landmarks\"\npqfile = f\"{inpdir}/{file_id}.parquet\"\nseq_refs = df.loc[df.file_id == file_id]\nseqs = load_relevant_data_subset(pqfile)\n\nseq_id = seq_refs.sequence_id.iloc[0]\nframes = seqs.iloc[seqs.index == seq_id]\nphrase = str(df.loc[df.sequence_id == seq_id].phrase.iloc[0])","metadata":{"_uuid":"69025248-a678-4026-b571-dab49e31a23b","_cell_guid":"6a4e8279-191d-4d6f-bbca-a45054d354c4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function()\ndef resize_pad(x):\n    if tf.shape(x)[0] < FRAME_LEN:\n        x = tf.pad(x, ([[0, FRAME_LEN-tf.shape(x)[0]], [0, 0], [0, 0]]), constant_values=float(\"NaN\"))\n    else:\n        x = tf.image.resize(x, (FRAME_LEN, tf.shape(x)[1]))\n    return x\n\n@tf.function(jit_compile=True)\ndef pre_process0(x):\n    lip_x = tf.gather(x, LIP_IDX_X, axis=1)\n    lip_y = tf.gather(x, LIP_IDX_Y, axis=1)\n    lip_z = tf.gather(x, LIP_IDX_Z, axis=1)\n\n    rhand_x = tf.gather(x, RHAND_IDX_X, axis=1)\n    rhand_y = tf.gather(x, RHAND_IDX_Y, axis=1)\n    rhand_z = tf.gather(x, RHAND_IDX_Z, axis=1)\n    \n    lhand_x = tf.gather(x, LHAND_IDX_X, axis=1)\n    lhand_y = tf.gather(x, LHAND_IDX_Y, axis=1)\n    lhand_z = tf.gather(x, LHAND_IDX_Z, axis=1)\n\n    rpose_x = tf.gather(x, RPOSE_IDX_X, axis=1)\n    rpose_y = tf.gather(x, RPOSE_IDX_Y, axis=1)\n    rpose_z = tf.gather(x, RPOSE_IDX_Z, axis=1)\n    \n    lpose_x = tf.gather(x, LPOSE_IDX_X, axis=1)\n    lpose_y = tf.gather(x, LPOSE_IDX_Y, axis=1)\n    lpose_z = tf.gather(x, LPOSE_IDX_Z, axis=1)\n    \n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis], lip_z[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis], rhand_z[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis], lhand_z[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis], rpose_z[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis], lpose_z[..., tf.newaxis]], axis=-1)\n    \n    hand = tf.concat([rhand, lhand], axis=1)\n    hand = tf.where(tf.math.is_nan(hand), 0.0, hand)\n    mask = tf.math.not_equal(tf.reduce_sum(hand, axis=[1, 2]), 0.0)\n\n    lip = lip[mask]\n    rhand = rhand[mask]\n    lhand = lhand[mask]\n    rpose = rpose[mask]\n    lpose = lpose[mask]\n\n    return lip, rhand, lhand, rpose, lpose\n\n\n@tf.function()\ndef pre_process1(lip, rhand, lhand, rpose, lpose):\n    lip   = resize_pad((( lip) - LIPM) / LIPS)\n    rhand = resize_pad(((rhand) - RHM) / RHS)\n    lhand = resize_pad(((lhand) - LHM) / LHS)\n    rpose = resize_pad(((rpose) - RPM) / RPS)\n    lpose = resize_pad(((lpose) - LPM) / LPS)\n    \n    \n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    \n    \n    a=tf.reshape(x,(-1,92,3))\n    X=a[:,:,0]\n    Y=a[:,:,1]\n\n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    x = tf.where(tf.math.is_nan(x), 0.0, x)\n    \n    return x\n\n\npre0 = pre_process0(frames)\npre1 = pre_process1(*pre0)\nINPUT_SHAPE = list(pre1.shape)\nprint(INPUT_SHAPE)","metadata":{"_uuid":"66e63f4d-a835-4d3f-b525-72a2b8ed57c2","_cell_guid":"b72a9d1c-ba62-4556-884b-6582cc18fd68","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def interp1d_(x, target_len, method='random'):\n    length = tf.shape(x)[1]\n    target_len = tf.maximum(1,target_len)\n    if method == 'random':\n        if tf.random.uniform(()) < 0.33:\n            x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'bilinear')\n        else:\n            if tf.random.uniform(()) < 0.5:\n                x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'bicubic')\n            else:\n                x = tf.image.resize(x, (target_len,tf.shape(x)[1]),'nearest')\n    else:\n        x = tf.image.resize(x, (target_len,tf.shape(x)[1]),method)\n    return x\n\n\ndef resample(x, rate):\n    length = tf.shape(x)[0]\n    new_size = tf.cast(rate*tf.cast(length,tf.float32), tf.int32)\n    new_x = interp1d_(x, new_size)\n    return new_x\n\nMAX_LEN=FRAME_LEN\nlength=MAX_LEN\ndef temporal_crop(x,offset):\n    x = x[offset:offset+length]\n    return x\n\n@tf.function()\ndef pre_processtrain(lip, rhand, lhand, rpose, lpose):\n    rate=(0.8,1.2)\n    rate = tf.random.uniform((), rate[0], rate[1])\n    \n    l = tf.shape(lip)[0]\n    offset = tf.random.uniform((), 0, tf.clip_by_value(l-length,1,length), dtype=tf.int32)\n    \n    lip   = (((temporal_crop(resample(lip,rate),offset)) - LIPM) / LIPS)\n    rhand = (((temporal_crop(resample(rhand,rate),offset)) - RHM) / RHS)\n    lhand = (((temporal_crop(resample(lhand,rate),offset)) - LHM) / LHS)\n    rpose = (((temporal_crop(resample(rpose,rate),offset)) - RPM) / RPS)\n    lpose = (((temporal_crop(resample(lpose,rate),offset)) - LPM) / LPS)\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    \n    a=tf.reshape(x,(-1,92,3))\n    X=a[:,:,0]\n    Y=a[:,:,1]\n\n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:15:53.780138Z","iopub.execute_input":"2023-08-24T20:15:53.780483Z","iopub.status.idle":"2023-08-24T20:15:53.808664Z","shell.execute_reply.started":"2023-08-24T20:15:53.780453Z","shell.execute_reply":"2023-08-24T20:15:53.807266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AUGMENTATIONS","metadata":{"_uuid":"bc4a2ade-72b8-4529-b145-1d155c174f1c","_cell_guid":"74195772-e53a-421a-adeb-75b6a25503b4","trusted":true}},{"cell_type":"code","source":"MAXSHIFT=1\nMINSHIFT=-1\nANGLE_DEGREE_RANGE=45\nMAX_SHEAR=0.2\nMIN_SHEAR=-0.2\n\n\n\nX_idx_after_preprocess=list(range(0,40))  + list(range(120,141)) + list(range(183,204)) + list(range(246,251)) +list(range(261,266)) \nY_idx_after_preprocess=list(range(40,80)) + list(range(141,162)) + list(range(204,225)) + list(range(251,256)) +list(range(266,271)) \nZ_idx_after_preprocess=list(range(80,120))+ list(range(162,183)) + list(range(225,246)) + list(range(256,261)) +list(range(271,276)) \n\nLIP_IDX  = list(range(0,40))\nRHAND_IDX = list(range(40,61))\nLHAND_IDX = list(range(61,82))\nRPOSE_IDX = list(range(82,87))\nLPOSE_IDX = list(range(87,92))\n\n#FLIP\n@tf.function()\ndef random_x_flip(x):\n    if tf.random.uniform([])<0.5:\n        a=tf.reshape(x,(-1,92,NUM_AXIS))\n        X=a[:,:,0]\n        Y=a[:,:,1]\n        \n        X=X*-1\n\n        lip_x = tf.gather(X, LIP_IDX, axis=1)\n        lip_y = tf.gather(Y, LIP_IDX, axis=1)\n        \n        rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n        rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n        \n        lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n        lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n        rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n        rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n        \n        lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n        lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n        \n        lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n        rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n        lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n        rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n        lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n        x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n        s = tf.shape(x)\n        x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x\n\n\n\n\n#SHIFT\n@tf.function()\ndef random_shift(x):\n    x=x+tf.random.uniform([],minval=MINSHIFT,maxval=MAXSHIFT)\n    return x\n\n\n\n#ROTATE\n@tf.function()\ndef rotate_xyz(x):\n    angle=tf.random.uniform([],minval=-ANGLE_DEGREE_RANGE,maxval=ANGLE_DEGREE_RANGE)\n    radian = angle/180*np.pi\n\n    rotation_matrix = tf.stack([(tf.cos(radian), -tf.sin(radian)), (tf.sin(radian), tf.cos(radian))], axis=0)\n\n\n    a=tf.reshape(x,(-1,92,NUM_AXIS))\n    \n    X=a[:,:,0]\n    Y=a[:,:,1]\n\n\n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n    amd=tf.stack([lip_x,lip_y],axis=-1)@rotation_matrix\n    lip_x=amd[:,:,0]\n    lip_y=amd[:,:,1]\n\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n    amd=tf.stack([rhand_x,rhand_y],axis=-1)@rotation_matrix\n    rhand_x=amd[:,:,0]\n    rhand_y=amd[:,:,1]\n    \n    \n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n    amd=tf.stack([lhand_x,lhand_y],axis=-1)@rotation_matrix\n    lhand_x=amd[:,:,0]\n    lhand_y=amd[:,:,1]\n\n    \n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n    amd=tf.stack([rpose_x,rpose_y],axis=-1)@rotation_matrix\n    rpose_x=amd[:,:,0]\n    rpose_y=amd[:,:,1]\n   \n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n    amd=tf.stack([lpose_x,lpose_y],axis=-1)@rotation_matrix\n    lpose_x=amd[:,:,0]\n    lpose_y=amd[:,:,1]\n\n    \n        \n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x\n\n\n#SHEAR\n@tf.function()\ndef random_x_shear(x):\n    a=tf.reshape(x,(-1,92,NUM_AXIS))\n\n    X0 = a[:,:,0]\n    Y0 = a[:,:,1]\n\n    sx = tf.random.uniform([],minval=MIN_SHEAR,maxval=MAX_SHEAR)\n    sy = tf.random.uniform([],minval=MIN_SHEAR,maxval=MAX_SHEAR)\n\n    X = X0\n    Y = Y0 + sy*X0\n\n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x\n@tf.function()\ndef random_y_shear(x):\n    a=tf.reshape(x,(-1,92,NUM_AXIS))\n\n    X0 = a[:,:,0]\n    Y0 = a[:,:,1]\n\n    sx = tf.random.uniform([],minval=MIN_SHEAR,maxval=MAX_SHEAR)\n    sy = tf.random.uniform([],minval=MIN_SHEAR,maxval=MAX_SHEAR)\n\n    X = X0 + sx*Y0\n    Y = Y0 \n\n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x\n\n\n@tf.function()\ndef temporal_mask(x, size=(0.2,0.4), mask_value=float(0)):\n    if tf.random.uniform(())<0.75:\n        \n        a =tf.reshape(x,(-1,92,NUM_AXIS))\n        l = tf.shape(x)[0]\n        \n        mask_size = tf.random.uniform((), *size)\n        mask_size = tf.cast(tf.cast(l, tf.float32) * mask_size, tf.int32)\n        mask_offset = tf.random.uniform((), 0, tf.clip_by_value(l-mask_size,1,l), dtype=tf.int32)\n        a = tf.tensor_scatter_nd_update(a,tf.range(mask_offset, mask_offset+mask_size)[...,None],tf.fill([mask_size,92,NUM_AXIS],mask_value))\n\n    \n        X = a[:,:,0]\n        Y = a[:,:,1]\n\n        lip_x = tf.gather(X, LIP_IDX, axis=1)\n        lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n        rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n        rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n        lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n        lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n        rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n        rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n        lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n        lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n        lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n        rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n        lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n        rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n        lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n        x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n        s = tf.shape(x)\n        x = tf.reshape(x, (s[0], s[1]*s[2]))\n    return x\n\n@tf.function()\ndef spatial_mask(x):\n    if tf.random.uniform(())<0.75:\n        x =tf.reshape(x,(-1,92,NUM_AXIS))\n        \n        size=(0.2,0.4)\n        mask_value=float(0)\n        mask_offset_y = tf.random.uniform(())\n        mask_offset_x = tf.random.uniform(())\n        mask_size = tf.random.uniform((), *size)\n        mask_x = (mask_offset_x<x[...,0]) & (x[...,0] < mask_offset_x + mask_size)\n        mask_y = (mask_offset_y<x[...,1]) & (x[...,1] < mask_offset_y + mask_size)\n        mask = mask_x & mask_y\n        x=tf.where(mask[...,None], mask_value, x)\n    \n        X = x[:,:,0]\n        Y = x[:,:,1]\n\n        lip_x = tf.gather(X, LIP_IDX, axis=1)\n        lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n        rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n        rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n        lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n        lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n        rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n        rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n        lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n        lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n        lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n        rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n        lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n        rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n        lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n        x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n        s = tf.shape(x)\n        x = tf.reshape(x, (s[0], s[1]*s[2]))\n    \n    return x\n    \n    \n@tf.function()\ndef augment(x,y):\n    #Temporal\n    x = temporal_mask(x)\n    #spacial\n    x = spatial_mask(x)\n    #Rotate\n    x = rotate_xyz(x)\n    #Flip\n    x = random_x_flip(x)\n    #Shift\n    x = random_shift(x)\n    #Shear\n    x = random_x_shear(x)\n    x = random_y_shear(x)\n    \n    \n    x =tf.reshape(x,(-1,92,NUM_AXIS))\n        \n    \n    \n    X = x[:,:,0]\n    Y = x[:,:,1]\n    \n    lip_x = tf.gather(X, LIP_IDX, axis=1)\n    lip_y = tf.gather(Y, LIP_IDX, axis=1)\n\n    rhand_x = tf.gather(X, RHAND_IDX, axis=1)\n    rhand_y = tf.gather(Y, RHAND_IDX, axis=1)\n\n    lhand_x = tf.gather(X, LHAND_IDX, axis=1)\n    lhand_y = tf.gather(Y, LHAND_IDX, axis=1)\n\n    rpose_x = tf.gather(X, RPOSE_IDX, axis=1)\n    rpose_y = tf.gather(Y, RPOSE_IDX, axis=1)\n\n    lpose_x = tf.gather(X, LPOSE_IDX, axis=1)\n    lpose_y = tf.gather(Y, LPOSE_IDX, axis=1)\n\n    lip   = tf.concat([lip_x[..., tf.newaxis], lip_y[..., tf.newaxis]], axis=-1)\n    rhand = tf.concat([rhand_x[..., tf.newaxis], rhand_y[..., tf.newaxis]], axis=-1)\n    lhand = tf.concat([lhand_x[..., tf.newaxis], lhand_y[..., tf.newaxis]], axis=-1)\n    rpose = tf.concat([rpose_x[..., tf.newaxis], rpose_y[..., tf.newaxis]], axis=-1)\n    lpose = tf.concat([lpose_x[..., tf.newaxis], lpose_y[..., tf.newaxis]], axis=-1)\n\n    lip   = resize_pad(lip) \n    rhand = resize_pad(rhand)\n    lhand = resize_pad(lhand)\n    rpose = resize_pad(rpose)\n    lpose = resize_pad(lpose)\n    \n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    x = tf.where(tf.math.is_nan(x), 0.0, x)\n    return x,y","metadata":{"_uuid":"f3eb3195-6df1-4d58-b843-969718a49282","_cell_guid":"4d71055d-eb1a-4e33-9f63-88ae854a5d62","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:15:53.811634Z","iopub.execute_input":"2023-08-24T20:15:53.812047Z","iopub.status.idle":"2023-08-24T20:15:53.90882Z","shell.execute_reply.started":"2023-08-24T20:15:53.812015Z","shell.execute_reply":"2023-08-24T20:15:53.907204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_fn(record_bytes):\n    schema = {\n        \"lip\": tf.io.VarLenFeature(tf.float32),\n        \"rhand\": tf.io.VarLenFeature(tf.float32),\n        \"lhand\": tf.io.VarLenFeature(tf.float32),\n        \"rpose\": tf.io.VarLenFeature(tf.float32),\n        \"lpose\": tf.io.VarLenFeature(tf.float32),\n        \"phrase\": tf.io.VarLenFeature(tf.int64)\n    }\n    x = tf.io.parse_single_example(record_bytes, schema)\n\n    lip = tf.reshape(tf.sparse.to_dense(x[\"lip\"]), (-1, 40, 3))\n    rhand = tf.reshape(tf.sparse.to_dense(x[\"rhand\"]), (-1, 21, 3))\n    lhand = tf.reshape(tf.sparse.to_dense(x[\"lhand\"]), (-1, 21, 3))\n    rpose = tf.reshape(tf.sparse.to_dense(x[\"rpose\"]), (-1, 5, 3))\n    lpose = tf.reshape(tf.sparse.to_dense(x[\"lpose\"]), (-1, 5, 3))\n    phrase = tf.sparse.to_dense(x[\"phrase\"])\n\n    return lip, rhand, lhand, rpose, lpose, phrase\n\ndef pre_process_fntrain(lip, rhand, lhand, rpose, lpose, phrase):\n    phrase = tf.pad(phrase, [[0, MAX_PHRASE_LENGTH-tf.shape(phrase)[0]]], constant_values=pad_token_idx)\n    return pre_processtrain(lip, rhand, lhand, rpose, lpose), phrase\n\ndef pre_process_fn(lip, rhand, lhand, rpose, lpose, phrase):\n    phrase = tf.pad(phrase, [[0, MAX_PHRASE_LENGTH-tf.shape(phrase)[0]]], constant_values=pad_token_idx)\n    return pre_process1(lip, rhand, lhand, rpose, lpose), phrase\n    \n\ntrain_batch_size = 128\nval_batch_size = 128\n\n    \n    \ntffiles=glob.glob(BASE_PATH_DATA+\"tfds/*\")\nval_len = 1\n\nval_files=[i for i in tffiles if i[len(BASE_PATH_DATA+\"tfds/\"):]==\"5414471.tfrecord\"]\ntrain_files=[i for i in tffiles if i not in val_files]\nrandom.shuffle(train_files)\n\ntrain_batch_size = 128\nval_batch_size = 128\n\ntrain_dataset =  tf.data.TFRecordDataset(train_files).shuffle(2000).prefetch(tf.data.AUTOTUNE).map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE).map(pre_process_fntrain, num_parallel_calls=tf.data.AUTOTUNE).map(augment).batch(train_batch_size).prefetch(tf.data.AUTOTUNE)\nval_dataset =  tf.data.TFRecordDataset([val_files]).prefetch(tf.data.AUTOTUNE).map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE).map(pre_process_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(val_batch_size).prefetch(tf.data.AUTOTUNE)\n\nbatch = next(iter(val_dataset))\nbatch[0].shape, batch[1].shape","metadata":{"_uuid":"2f7fe5b9-4720-4b2c-80ce-0a08aa1a2523","_cell_guid":"c05cba01-5f5f-4913-a82a-a535632ac2f5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:15:53.910765Z","iopub.execute_input":"2023-08-24T20:15:53.911118Z","iopub.status.idle":"2023-08-24T20:16:00.663372Z","shell.execute_reply.started":"2023-08-24T20:15:53.911088Z","shell.execute_reply":"2023-08-24T20:16:00.662507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tffiles1=glob.glob(\"/kaggle/input/makingdf-with/tfds1/*\")","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:00.665176Z","iopub.execute_input":"2023-08-24T20:16:00.665603Z","iopub.status.idle":"2023-08-24T20:16:01.069183Z","shell.execute_reply.started":"2023-08-24T20:16:00.665564Z","shell.execute_reply":"2023-08-24T20:16:01.068117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_files)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:01.071153Z","iopub.execute_input":"2023-08-24T20:16:01.071597Z","iopub.status.idle":"2023-08-24T20:16:01.079344Z","shell.execute_reply.started":"2023-08-24T20:16:01.071557Z","shell.execute_reply":"2023-08-24T20:16:01.078183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"/kaggle/input/aslfr-preprocess-dataset-tfrecords-mean-std-mine/tfds/33432165.tfrecord\"","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:01.081071Z","iopub.execute_input":"2023-08-24T20:16:01.081696Z","iopub.status.idle":"2023-08-24T20:16:01.093918Z","shell.execute_reply.started":"2023-08-24T20:16:01.081652Z","shell.execute_reply":"2023-08-24T20:16:01.092932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for example,phrase in train_dataset:\n    print(example.shape)\n    break\nx=example[7]\nprint(x)\nx=tf.reshape(x,(-1,92,NUM_AXIS))\nX=tf.gather(x[:,:,0],RHAND_IDX,axis=1)[0:20]\nY=tf.gather(x[:,:,1],RHAND_IDX,axis=1)[0:20]\nframes = tf.concat([X,Y],axis=1)\nanimate_frames(frames,edges)","metadata":{"_uuid":"9ebfb9e6-8d6e-434c-ac4b-ec14b48e3dbc","_cell_guid":"8d1f6377-04e8-4106-9350-7fd9e302aa00","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:01.095148Z","iopub.execute_input":"2023-08-24T20:16:01.095449Z","iopub.status.idle":"2023-08-24T20:16:09.435864Z","shell.execute_reply.started":"2023-08-24T20:16:01.095425Z","shell.execute_reply":"2023-08-24T20:16:09.43454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for example,phrase in train_dataset:\n    print(example.shape)\n    break\nx=example[7]\nprint(x)\nx=tf.reshape(x,(-1,92,NUM_AXIS))\nX=tf.gather(x[:,:,0],RHAND_IDX,axis=1)[0:20]\nY=tf.gather(x[:,:,1],RHAND_IDX,axis=1)[0:20]\nframes = tf.concat([X,Y],axis=1)\nanimate_frames(frames,edges)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:09.440692Z","iopub.execute_input":"2023-08-24T20:16:09.44114Z","iopub.status.idle":"2023-08-24T20:16:14.731188Z","shell.execute_reply.started":"2023-08-24T20:16:09.441099Z","shell.execute_reply":"2023-08-24T20:16:14.729896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"49f6256e-9768-4803-afb4-f088b338c696","_cell_guid":"283a49e7-a6b1-4fd0-aba6-85d3f0f40fc9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL","metadata":{"_uuid":"1474d5b7-ac11-438b-ada2-1bd30429d180","_cell_guid":"46b1e494-7bc9-41c0-a4ce-2e7d1e438c04","trusted":true}},{"cell_type":"code","source":"#Channel Attention\nclass ECA(tf.keras.layers.Layer):\n    def __init__(self, kernel_size=5, **kwargs):\n        super().__init__(**kwargs)\n        self.supports_masking = True\n        self.kernel_size = kernel_size\n        self.conv = tf.keras.layers.Conv1D(1, kernel_size=kernel_size, strides=1, padding=\"same\", use_bias=False)\n\n    def call(self, inputs, mask=None):\n        nn = tf.keras.layers.GlobalAveragePooling1D()(inputs, mask=mask)\n        nn = tf.expand_dims(nn, -1)\n        nn = self.conv(nn)\n        nn = tf.squeeze(nn, -1)\n        nn = tf.nn.sigmoid(nn)\n        nn = nn[:,None,:]\n        return inputs * nn\n\n#a separate filter to each input channel. This is different from a standard convolution, which applies the same filter to all input channels. \n#Depthwise convolutions are computationally efficient and can be \n#effective in capturing fine-grained features.\nclass CausalDWConv1D(tf.keras.layers.Layer):\n    def __init__(self, \n        kernel_size=17,\n        dilation_rate=1,\n        use_bias=False,\n        depthwise_initializer='glorot_uniform',\n        name='', **kwargs):\n        super().__init__(name=name,**kwargs)\n        self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n        self.dw_conv = tf.keras.layers.DepthwiseConv1D(\n                            kernel_size,\n                            strides=1,\n                            dilation_rate=dilation_rate,\n                            padding='valid',\n                            use_bias=use_bias,\n                            depthwise_initializer=depthwise_initializer,\n                            name=name + '_dwconv')\n        \n        self.supports_masking = True\n        \n    def call(self, inputs):\n        x = self.causal_pad(inputs)\n        x = self.dw_conv(x)\n        return x\n\ndef Conv1DBlock(channel_size,\n          kernel_size,\n          dilation_rate=1,\n          drop_rate=0.0,\n          expand_ratio=2,\n          se_ratio=0.25,\n          activation='swish',\n          name=None):\n    if name is None:\n        name = str(tf.keras.backend.get_uid(\"mbblock\"))\n    def apply(inputs):\n        channels_in = tf.keras.backend.int_shape(inputs)[-1]\n        channels_expand = channels_in * expand_ratio\n\n        skip = inputs\n\n        x = tf.keras.layers.Dense(\n            channels_expand,\n            use_bias=True,\n            activation=activation,\n            name=name + '_expand_conv')(inputs)\n\n        # Depthwise Convolution\n        x = CausalDWConv1D(kernel_size,\n            dilation_rate=dilation_rate,\n            use_bias=False,\n            name=name + '_dwconv')(x)\n\n        x = tf.keras.layers.BatchNormalization(momentum=0.95, name=name + '_bn')(x)\n\n        x  = ECA()(x)\n\n        x = tf.keras.layers.Dense(\n            channel_size,\n            use_bias=True,\n            name=name + '_project_conv')(x)\n\n        if drop_rate > 0:\n            x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1), name=name + '_drop')(x)\n\n        if (channels_in == channel_size):\n            x = tf.keras.layers.add([x, skip], name=name + '_add')\n        return x\n\n    return apply\n\nclass MultiHeadSelfAttention(tf.keras.layers.Layer):\n    def __init__(self, dim=256, num_heads=4, dropout=0, **kwargs):\n        super().__init__(**kwargs)\n        self.dim = dim\n        self.scale = self.dim ** -0.5\n        self.num_heads = num_heads\n        self.qkv = tf.keras.layers.Dense(3 * dim, use_bias=False)\n        self.drop1 = tf.keras.layers.Dropout(dropout)\n        self.proj = tf.keras.layers.Dense(dim, use_bias=False)\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        qkv = self.qkv(inputs)\n        qkv = tf.keras.layers.Permute((2, 1, 3))(tf.keras.layers.Reshape((-1, self.num_heads, self.dim * 3 // self.num_heads))(qkv))\n        q, k, v = tf.split(qkv, [self.dim // self.num_heads] * 3, axis=-1)\n\n        attn = tf.matmul(q, k, transpose_b=True) * self.scale\n\n        if mask is not None:\n            mask = mask[:, None, None, :]\n\n        attn = tf.keras.layers.Softmax(axis=-1)(attn, mask=mask)\n        attn = self.drop1(attn)\n\n        x = attn @ v\n        x = tf.keras.layers.Reshape((-1, self.dim))(tf.keras.layers.Permute((2, 1, 3))(x))\n        x = self.proj(x)\n        return x\n\n\ndef TransformerBlock(dim=256, num_heads=6, expand=4, attn_dropout=0.2, drop_rate=0.2, activation='swish'):\n    def apply(inputs):\n        x = inputs\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n        x = MultiHeadSelfAttention(dim=dim,num_heads=num_heads,dropout=attn_dropout)(x)\n        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n        x = tf.keras.layers.Add()([inputs, x])\n        attn_out = x\n\n        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n        x = tf.keras.layers.Dense(dim*expand, use_bias=False, activation=activation)(x)\n        x = tf.keras.layers.Dense(dim, use_bias=False)(x)\n        x = tf.keras.layers.Dropout(drop_rate, noise_shape=(None,1,1))(x)\n        x = tf.keras.layers.Add()([attn_out, x])\n        return x\n    return apply\n\ndef positional_encoding(maxlen, num_hid):\n        depth = num_hid/2\n        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n        angle_rads = tf.linalg.matmul(positions, angle_rates)\n        pos_encoding = tf.concat(\n          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n          axis=-1)\n        return pos_encoding\n    \nclass LateDropout(tf.keras.layers.Layer):\n    def __init__(self, rate, noise_shape=None, start_step=0, **kwargs):\n        super().__init__(**kwargs)\n        self.supports_masking = True\n        self.rate = rate\n        self.start_step = start_step\n        self.dropout = tf.keras.layers.Dropout(rate, noise_shape=noise_shape)\n      \n    def build(self, input_shape):\n        super().build(input_shape)\n        agg = tf.VariableAggregation.ONLY_FIRST_REPLICA\n        self._train_counter = tf.Variable(0, dtype=\"int64\", aggregation=agg, trainable=False)\n\n    def call(self, inputs, training=False):\n        x = tf.cond(self._train_counter < self.start_step, lambda:inputs, lambda:self.dropout(inputs, training=training))\n        if training:\n            self._train_counter.assign_add(1)\n        return x","metadata":{"_uuid":"fea0ce9d-a64d-4192-a83c-5f11d9e4777f","_cell_guid":"d92c3c71-0672-48e3-abdd-9a0a79c4f598","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:14.732981Z","iopub.execute_input":"2023-08-24T20:16:14.733521Z","iopub.status.idle":"2023-08-24T20:16:14.778087Z","shell.execute_reply.started":"2023-08-24T20:16:14.73349Z","shell.execute_reply":"2023-08-24T20:16:14.776516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CTCLoss(labels, logits):\n    label_length = tf.reduce_sum(tf.cast(labels != pad_token_idx, tf.int32), axis=-1)\n    logit_length = tf.ones(tf.shape(logits)[0], dtype=tf.int32) * tf.shape(logits)[1]\n    loss = tf.nn.ctc_loss(\n            labels=labels,\n            logits=logits,\n            label_length=label_length,\n            logit_length=logit_length,\n            blank_index=pad_token_idx,\n            logits_time_major=False\n        )\n    loss = tf.reduce_mean(loss)\n    return loss","metadata":{"_uuid":"a632a06e-aa7c-40a4-b778-14e70287ce1c","_cell_guid":"f42a03b7-af07-4288-8c21-fe3fab43ff7f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:14.779899Z","iopub.execute_input":"2023-08-24T20:16:14.780455Z","iopub.status.idle":"2023-08-24T20:16:14.795402Z","shell.execute_reply.started":"2023-08-24T20:16:14.78042Z","shell.execute_reply":"2023-08-24T20:16:14.794214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"inp = tf.keras.Input(INPUT_SHAPE)\n\nx = tf.keras.layers.Masking(mask_value=0.0)(inp)\nx = tf.keras.layers.Dense(dim, use_bias=False,name='stem_conv')(x) + positional_encoding(INPUT_SHAPE[0], dim)\npe = tf.cast(positional_encoding(INPUT_SHAPE[0], dim), dtype=x.dtype)\nx = x + pe\nx = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n\nfor i in range(NUM_BLOCKS):\n    x = Conv1DBlock(dim, 11, drop_rate=DROP_RATE)(x)\n    x = Conv1DBlock(dim,  5, drop_rate=DROP_RATE)(x)\n    x = Conv1DBlock(dim,  3, drop_rate=DROP_RATE)(x)\n    x = TransformerBlock(dim, expand=2)(x)\n\n\nx = tf.keras.layers.Dense(dim*2,activation='relu',name='top_conv')(x)\nx = tf.keras.layers.Dropout(0.8)(x)\nx = tf.keras.layers.Dense(len(char_to_num))(x)\n\nmodel = tf.keras.Model(inp, x)\n\nloss = CTCLoss\n\n# Adam Optimizer\noptimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4)\noptimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n\nmodel.compile(loss=loss, optimizer=optimizer)\n\nreturn model\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:14.797095Z","iopub.execute_input":"2023-08-24T20:16:14.797717Z","iopub.status.idle":"2023-08-24T20:16:14.814454Z","shell.execute_reply.started":"2023-08-24T20:16:14.79765Z","shell.execute_reply":"2023-08-24T20:16:14.813014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j=1\nk=0.059\nfor i in range(6):\n    print(j)\n    j=j-k*1","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:14.816117Z","iopub.execute_input":"2023-08-24T20:16:14.818999Z","iopub.status.idle":"2023-08-24T20:16:14.830742Z","shell.execute_reply.started":"2023-08-24T20:16:14.818953Z","shell.execute_reply":"2023-08-24T20:16:14.829592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"92*2","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:14.83233Z","iopub.execute_input":"2023-08-24T20:16:14.833077Z","iopub.status.idle":"2023-08-24T20:16:14.845089Z","shell.execute_reply.started":"2023-08-24T20:16:14.833036Z","shell.execute_reply":"2023-08-24T20:16:14.843764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_SHAPE=example[0].shape\n\nDROP_RATE=0.4\nNUM_BLOCKS=3\n\n\ndef get_model(dim = 384):\n    inp = tf.keras.Input(INPUT_SHAPE)\n    \n    x = tf.keras.layers.Masking(mask_value=0.0)(inp)\n    x = tf.keras.layers.Dense(dim, use_bias=False, name='stem_conv')(x)\n    \n    pe = tf.cast(positional_encoding(INPUT_SHAPE[0], dim), dtype=x.dtype)\n    x = x + pe\n    \n    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n    \n    for i in range(NUM_BLOCKS):\n        x = Conv1DBlock(dim, 11, drop_rate=DROP_RATE)(x)\n        x = Conv1DBlock(dim,  5, drop_rate=DROP_RATE)(x)\n        x = Conv1DBlock(dim,  3, drop_rate=DROP_RATE)(x)\n        x = TransformerBlock(dim, expand=2)(x)\n\n\n    x = tf.keras.layers.Dense(dim*2,activation='relu',name='top_conv')(x)\n    x = tf.keras.layers.Dropout(0.8)(x)\n    x = tf.keras.layers.Dense(len(char_to_num))(x)\n\n    model = tf.keras.Model(inp, x)\n\n    loss = CTCLoss\n    \n    # Adam Optimizer\n    optimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4)\n    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n\n    model.compile(loss=loss, optimizer=optimizer)\n\n    return model\n\ntf.keras.backend.clear_session()\n\nmodel1 = get_model()\nmodel1(batch[0])\n\nmodel2 = get_model()\nmodel2(batch[0])\n\nmodel3 = get_model()\nmodel3(batch[0])\n\nmodel = get_model()\nmodel(batch[0])\nmodel.summary()","metadata":{"_uuid":"be4b532e-c0a3-4259-9710-dd54750634cf","_cell_guid":"b7b0a9bd-5ced-4ea6-afd4-a833baf40fe6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:14.846693Z","iopub.execute_input":"2023-08-24T20:16:14.847259Z","iopub.status.idle":"2023-08-24T20:16:44.879718Z","shell.execute_reply.started":"2023-08-24T20:16:14.84722Z","shell.execute_reply":"2023-08-24T20:16:44.878388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num_to_char_fn(y):\n    return [num_to_char.get(x, \"\") for x in y]\n\n@tf.function()\ndef decode_phrase(pred):\n    x = tf.argmax(pred, axis=1)\n    diff = tf.not_equal(x[:-1], x[1:])\n    adjacent_indices = tf.where(diff)[:, 0]\n    x = tf.gather(x, adjacent_indices)\n    mask = x != pad_token_idx\n    x = tf.boolean_mask(x, mask, axis=0)\n    return x\n\n# A utility function to decode the output of the network\ndef decode_batch_predictions(pred):\n    output_text = []\n    for result in pred:\n        result = \"\".join(num_to_char_fn(decode_phrase(result).numpy()))\n        output_text.append(result)\n    return output_text","metadata":{"_uuid":"2bbc66ab-e98c-4ce3-9361-ed50ad5e4bae","_cell_guid":"b70b2277-7eef-4f9e-a91c-6cb4ac53d635","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:44.881474Z","iopub.execute_input":"2023-08-24T20:16:44.882433Z","iopub.status.idle":"2023-08-24T20:16:44.892794Z","shell.execute_reply.started":"2023-08-24T20:16:44.88239Z","shell.execute_reply":"2023-08-24T20:16:44.891574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open (\"/kaggle/input/asl-fingerspelling/character_to_prediction_index.json\", \"r\") as f:\n    character_map = json.load(f)\nrev_character_map = {j:i for i,j in character_map.items()}\n\n# A callback class to output a few transcriptions during training\nclass CallbackEval(tf.keras.callbacks.Callback):\n    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n\n    def __init__(self, dataset):\n        super().__init__()\n        self.dataset = dataset\n\n    def on_epoch_end(self, epoch: int, logs=None):\n        model.save_weights(\"model\"+str(epoch+1)+\".h5\")\n        predictions = []\n        targets = []\n        for batch in self.dataset:\n            X, y = batch\n            batch_predictions = model(X)\n            batch_predictions = decode_batch_predictions(batch_predictions)\n            predictions.extend(batch_predictions)\n            for label in y:\n                label =  \"\".join([rev_character_map.get(int(s),\"\") for s in label])\n                targets.append(label)\n\n        print(\"-\" * 100)\n        # for i in np.random.randint(0, len(predictions), 2):\n        L=[]\n        N=[]\n        for i in range(32):\n            print(f\"Target    : {targets[i]}\")\n            print(f\"Prediction: {predictions[i]}, len: {len(predictions[i])}, LEV: {lev.distance(targets[i], predictions[i])}\")\n            print(\"\")\n\n\n        for i in range(len(targets)):\n            N.append(len(targets[i]))\n            l=lev.distance(targets[i], predictions[i])\n            L.append(l)\n            \n        \n        print(\"\")\n        print(\"LEVDIST Total:\",sum(L))\n        print(\"LEVDIST Normalized:\",(sum(N) -sum(L))/sum(N))\n        print(\"\")\n\n# Callback function to check transcription on the val set.\nvalidation_callback = CallbackEval(val_dataset.take(1))","metadata":{"_uuid":"29ee3fec-5dd8-4097-81d2-836c3e506feb","_cell_guid":"acd834f5-2928-454c-83f1-b558e93dc5bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:44.894174Z","iopub.execute_input":"2023-08-24T20:16:44.894537Z","iopub.status.idle":"2023-08-24T20:16:44.914567Z","shell.execute_reply.started":"2023-08-24T20:16:44.894507Z","shell.execute_reply":"2023-08-24T20:16:44.913322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 600\nN_WARMUP_EPOCHS = 10\nLR_MAX = 1e-3\nWD_RATIO = 0.05\nWARMUP_METHOD = \"exp\"","metadata":{"_uuid":"ac4ffd4e-01db-4b1f-9164-e0810fa7d42a","_cell_guid":"f571d385-976e-430b-898e-bb37102d67e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:44.916319Z","iopub.execute_input":"2023-08-24T20:16:44.916724Z","iopub.status.idle":"2023-08-24T20:16:44.933374Z","shell.execute_reply.started":"2023-08-24T20:16:44.916691Z","shell.execute_reply":"2023-08-24T20:16:44.932064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    if current_step < num_warmup_steps:\n        if WARMUP_METHOD == 'log':\n            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n        else:\n            return lr_max * 2 ** -(num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n    \ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n# Plot Learning Rate Schedule\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)\n\n# Custom callback to update weight decay with learning rate\nclass WeightDecayCallback(tf.keras.callbacks.Callback):\n    def __init__(self, wd_ratio=WD_RATIO):\n        self.step_counter = 0\n        self.wd_ratio = wd_ratio\n    \n    def on_epoch_begin(self, epoch, logs=None):\n        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')","metadata":{"_uuid":"9891f6d6-d8d1-4d10-af80-3cad4d2815ea","_cell_guid":"8bb61713-f2ef-4988-9cbb-c22a21ac3449","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:44.935448Z","iopub.execute_input":"2023-08-24T20:16:44.935838Z","iopub.status.idle":"2023-08-24T20:16:48.662644Z","shell.execute_reply.started":"2023-08-24T20:16:44.935807Z","shell.execute_reply":"2023-08-24T20:16:48.661391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class earylstopatepoch(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch+1>=500:\n            self.model.stop_training = True\nesep=earylstopatepoch()","metadata":{"_uuid":"ac675145-3098-4d69-a37e-1a963b238ada","_cell_guid":"ee54c5c5-0ac8-463e-9062-7e1f82eae8ae","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-08-24T20:16:48.66437Z","iopub.execute_input":"2023-08-24T20:16:48.665155Z","iopub.status.idle":"2023-08-24T20:16:48.670471Z","shell.execute_reply.started":"2023-08-24T20:16:48.665122Z","shell.execute_reply":"2023-08-24T20:16:48.669143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\n\nmodel1.load_weights(\"/kaggle/input/xy-128frame-supplemental/model880.h5\")\n\n\nmodel2.load_weights(\"/kaggle/input/xy-128frame-supplemental/model900.h5\")\n\nmodel3.load_weights(\"/kaggle/input/xy-128frame-supplemental/model700.h5\")\n\nmodels = [model1,model2,model3]\n\nweights = [model_t.get_weights() for model_t in models]\n\nnew_weights = list()\nfor weights_list_tuple in zip(*weights): \n    new_weights.append(\n        np.array([np.array(w).mean(axis=0) for w in zip(*weights_list_tuple)])\n    )\n\n    \n    \n\nmodel.set_weights(new_weights)\nvalidation_callback.on_epoch_end(0,1)\nmodels=[model]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:16:48.67503Z","iopub.execute_input":"2023-08-24T20:16:48.675431Z","iopub.status.idle":"2023-08-24T20:17:00.45699Z","shell.execute_reply.started":"2023-08-24T20:16:48.675386Z","shell.execute_reply":"2023-08-24T20:17:00.45578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"path=\"/kaggle/input/xy-128frame-supplemental/model900.h5\"\nmodel.load_weights(path)\nmodels=[model]\nvalidation_callback.on_epoch_end(0,1)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:17:00.45855Z","iopub.execute_input":"2023-08-24T20:17:00.459704Z","iopub.status.idle":"2023-08-24T20:17:00.467099Z","shell.execute_reply.started":"2023-08-24T20:17:00.45964Z","shell.execute_reply":"2023-08-24T20:17:00.465868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"history = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=N_EPOCHS,\n    initial_epoch=150,\n    callbacks=[\n        validation_callback,\n        lr_callback,\n        WeightDecayCallback(),\n        esep\n    ]\n)\nmodels=[model]\"\"\"","metadata":{"_uuid":"08fadbf7-1c45-4f62-b201-b4424a972f73","_cell_guid":"4b9d5f57-7a47-40b7-8e3d-86322b4ed553","jupyter":{"outputs_hidden":false},"collapsed":false,"execution":{"iopub.status.busy":"2023-08-24T20:17:00.468752Z","iopub.execute_input":"2023-08-24T20:17:00.469387Z","iopub.status.idle":"2023-08-24T20:17:00.485222Z","shell.execute_reply.started":"2023-08-24T20:17:00.469304Z","shell.execute_reply":"2023-08-24T20:17:00.483817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function()\ndef pre_process1xyz(lip, rhand, lhand, rpose, lpose):\n    lip   = resize_pad((( lip) - LIPM) / LIPS)\n    rhand = resize_pad(((rhand) - RHM) / RHS)\n    lhand = resize_pad(((lhand) - LHM) / LHS)\n    rpose = resize_pad(((rpose) - RPM) / RPS)\n    lpose = resize_pad(((lpose) - LPM) / LPS)\n    \n    \n    x = tf.concat([lip, rhand, lhand, rpose, lpose], axis=1)\n    s = tf.shape(x)\n    x = tf.reshape(x, (s[0], s[1]*s[2]))\n    x = tf.where(tf.math.is_nan(x), 0.0, x)\n    return x\n\nINPUT_SHAPE=example[0].shape\n\nDROP_RATE=0.4\nNUM_BLOCKS=3\n\n\ndef get_model(dim = 384):\n    inp = tf.keras.Input((128,276))\n    \n    x = tf.keras.layers.Masking(mask_value=0.0)(inp)\n    x = tf.keras.layers.Dense(dim, use_bias=False, name='stem_conv')(x)\n    \n    pe = tf.cast(positional_encoding(INPUT_SHAPE[0], dim), dtype=x.dtype)\n    x = x + pe\n    \n    x = tf.keras.layers.BatchNormalization(momentum=0.95,name='stem_bn')(x)\n    \n    for i in range(NUM_BLOCKS):\n        x = Conv1DBlock(dim, 11, drop_rate=DROP_RATE)(x)\n        x = Conv1DBlock(dim,  5, drop_rate=DROP_RATE)(x)\n        x = Conv1DBlock(dim,  3, drop_rate=DROP_RATE)(x)\n        x = TransformerBlock(dim, expand=2)(x)\n\n\n    x = tf.keras.layers.Dense(dim*2,activation='relu',name='top_conv')(x)\n    x = tf.keras.layers.Dropout(0.8)(x)\n    x = tf.keras.layers.Dense(len(char_to_num))(x)\n\n    model = tf.keras.Model(inp, x)\n\n    loss = CTCLoss\n    \n    # Adam Optimizer\n    optimizer = tfa.optimizers.RectifiedAdam(sma_threshold=4)\n    optimizer = tfa.optimizers.Lookahead(optimizer, sync_period=5)\n\n    model.compile(loss=loss, optimizer=optimizer)\n\n    return model\n\ntf.keras.backend.clear_session()\n\nb=np.random.random((1,128,276))\n\nmodelxyz_1 = get_model()\nmodelxyz_1(b)\n\nmodelxyz_2 = get_model()\nmodelxyz_2(b)\n\n\nmodelxyz = get_model()\nmodelxyz(b)\nmodelxyz.summary()\n\nmodels = []\n\nmodelxyz_1.load_weights(\"/kaggle/input/xy-128frame-supplemental/xyzmodel650.h5\")\n\nmodelxyz_2.load_weights(\"/kaggle/input/xy-128frame-supplemental/xyzmodel880.h5\")\n\n#model3.load_weights(\"/kaggle/input/xy-128frame-supplemental/model700.h5\")\n\nmodels = [modelxyz_1,modelxyz_2]\n\nweights = [model_t.get_weights() for model_t in models]\n\nnew_weights = list()\nfor weights_list_tuple in zip(*weights): \n    new_weights.append(\n        np.array([np.array(w).mean(axis=0) for w in zip(*weights_list_tuple)])\n    )\n\nmodelxyz.set_weights(new_weights)\n\n\n\n\nmodels=[model,modelxyz]","metadata":{"execution":{"iopub.status.busy":"2023-08-24T20:21:07.706863Z","iopub.execute_input":"2023-08-24T20:21:07.708113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TFLiteModel(tf.Module):\n    def __init__(self, model):\n        super(TFLiteModel, self).__init__()\n        self.models = model\n    \n    @tf.function(input_signature=[tf.TensorSpec(shape=[None, len(SEL_COLS)], dtype=tf.float32, name='inputs')])\n    def __call__(self, inputs, training=False):\n        # Preprocess Data\n        x = tf.cast(inputs, tf.float32)\n        x = x[None]\n        x = tf.cond(tf.shape(x)[1] == 0, lambda: tf.zeros((1, 1, len(SEL_COLS))), lambda: tf.identity(x))\n        x = x[0]\n        x = pre_process0(x)\n        \n        x1 = pre_process1(*x)\n        x2 = pre_process1xyz(*x)\n        \n        x1 = tf.reshape(x1, INPUT_SHAPE)\n        x1 = x1[None]\n        \n        x2 = tf.reshape(x2, (128,276))\n        x2 = x2[None]\n        \n        x1  =self.models[0](x1)\n        x2  =self.models[1](x2)\n        \n        x = tf.concat([x1,x2],axis=0)\n        \n    \n        x = tf.reduce_max(x, axis=0, keepdims=True)\n        \n        \n        x = x[0]\n        x = decode_phrase(x)\n        x = tf.cond(tf.shape(x)[0] == 0, lambda: tf.zeros(1, tf.int64), lambda: tf.identity(x))\n        x = tf.one_hot(x, 59)\n        return {'outputs': x}\n\ntflitemodel_base = TFLiteModel(models)","metadata":{"_uuid":"2b67a6fb-5526-4368-a364-aa944267ae23","_cell_guid":"165dd180-c1fe-4b39-9b78-4e415a0cc9cd","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pqfiles = df.file_id.unique()\nval_len = int(0.05 * len(pqfiles))\ndef create_data_gen(file_ids, y_mul=1):\n    def gen():\n        for file_id in file_ids:\n            pqfile = f\"{inpdir}/{file_id}.parquet\"\n            seq_refs = df.loc[df.file_id == file_id]\n            seqs = load_relevant_data_subset(pqfile)\n\n            for seq_id in seq_refs.sequence_id:\n                x = seqs.iloc[seqs.index == seq_id].to_numpy()\n                y = str(df.loc[df.sequence_id == seq_id].phrase.iloc[0])\n                \n                r_nonan = np.sum(np.sum(np.isnan(x[:, RHAND_IDX_X]), axis = 1) == 0)\n                l_nonan = np.sum(np.sum(np.isnan(x[:, LHAND_IDX_X]), axis = 1) == 0)\n                no_nan = max(r_nonan, l_nonan)\n                \n                if y_mul*len(y)<no_nan:\n                    yield x, y\n    return gen\n\ntest_dataset = tf.data.Dataset.from_generator(create_data_gen(pqfiles[:val_len], 0),\n    output_signature=(tf.TensorSpec(shape=(None, len(SEL_COLS)), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.string))\n).prefetch(buffer_size=2000)\n\nfor frame, target in test_dataset.skip(100).take(10):\n    frame\n    break\ntflitemodel_base(frame)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras_model_converter = tf.lite.TFLiteConverter.from_keras_model(tflitemodel_base)\nkeras_model_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]#, tf.lite.OpsSet.SELECT_TF_OPS]\nkeras_model_converter.optimizations = [tf.lite.Optimize.DEFAULT]\nkeras_model_converter.target_spec.supported_types = [tf.float16]\ntflite_model = keras_model_converter.convert()\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)\n    \nwith open('inference_args.json', \"w\") as f:\n    json.dump({\"selected_columns\" : SEL_COLS}, f)\n    \n!zip submission.zip  './model.tflite' './inference_args.json'","metadata":{"_uuid":"8e086b86-c30f-4702-a39f-7c3612abbf56","_cell_guid":"7aa7b286-e32a-4475-b78b-4fc07a41db43","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open (\"inference_args.json\", \"r\") as f:\n    SEL_COLS = json.load(f)[\"selected_columns\"]\n    \ndef load_relevant_data_subset(pq_path):\n    return pd.read_parquet(pq_path, columns=SEL_COLS)\n\ndef create_data_gen(file_ids, y_mul=1):\n    def gen():\n        for file_id in file_ids:\n            pqfile = f\"{inpdir}/{file_id}.parquet\"\n            seq_refs = df.loc[df.file_id == file_id]\n            seqs = load_relevant_data_subset(pqfile)\n\n            for seq_id in seq_refs.sequence_id:\n                x = seqs.iloc[seqs.index == seq_id].to_numpy()\n                y = str(df.loc[df.sequence_id == seq_id].phrase.iloc[0])\n                \n                r_nonan = np.sum(np.sum(np.isnan(x[:, RHAND_IDX_X]), axis = 1) == 0)\n                l_nonan = np.sum(np.sum(np.isnan(x[:, LHAND_IDX_X]), axis = 1) == 0)\n                no_nan = max(r_nonan, l_nonan)\n                \n                if y_mul*len(y)<no_nan:\n                    yield x, y\n    return gen\n\npqfiles = df.file_id.unique()\nval_len = int(0.05 * len(pqfiles))\n\ntest_dataset = tf.data.Dataset.from_generator(create_data_gen(pqfiles[:val_len], 0),\n    output_signature=(tf.TensorSpec(shape=(None, len(SEL_COLS)), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.string))\n).prefetch(buffer_size=2000)","metadata":{"_uuid":"df593be4-cc31-4b0e-b3e8-34ecde29e17e","_cell_guid":"f932d36d-2e8f-46fd-96fd-a689e975c443","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(\"model.tflite\")\n\nREQUIRED_SIGNATURE = \"serving_default\"\nREQUIRED_OUTPUT = \"outputs\"\n\nwith open (BASE_PATH+\"character_to_prediction_index.json\", \"r\") as f:\n    character_map = json.load(f)\nrev_character_map = {j:i for i,j in character_map.items()}\n\nprediction_fn = interpreter.get_signature_runner(REQUIRED_SIGNATURE)\n\nfor frame, target in test_dataset.skip(100).take(10):\n    output = prediction_fn(inputs=frame)\n    prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n    target = target.numpy().decode(\"utf-8\")\n    print(\"pred =\", prediction_str, \"; target =\", target,\"; lev =\",lev.distance(prediction_str,target))","metadata":{"_uuid":"87840921-ec82-4044-b43b-de7e9306f189","_cell_guid":"f6c86d22-aae9-4990-9bc3-19ae22bb12b9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%timeit -n 10\noutput = prediction_fn(inputs=frame)","metadata":{"_uuid":"432e80fe-cfd6-4b40-a886-015fd74d9cb1","_cell_guid":"e72b8481-9d13-4139-8a68-3666d1e0a6b9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from Levenshtein import distance\n\nscores = []\nj=1\nfor i, (frame, target) in tqdm(enumerate(test_dataset.take(1000))):\n    output = prediction_fn(inputs=frame)\n    prediction_str = \"\".join([rev_character_map.get(s, \"\") for s in np.argmax(output[REQUIRED_OUTPUT], axis=1)])\n    target = target.numpy().decode(\"utf-8\")\n    score = (len(target) - distance(prediction_str, target)) / len(target)\n    scores.append(score)\n    if i % 50 == 0:\n        print(j,\" \",np.sum(scores) / len(scores))\n        j=j+1\n    \nscores = np.array(scores)\nprint(\"Mean : \",np.sum(scores) / len(scores))","metadata":{"_uuid":"c49f2ce7-06ab-40d4-bcf0-940019663f96","_cell_guid":"47dba731-2258-4092-a864-987a4f55c228","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}